---
title: "(WIP) Boundary Problems - Refining Solutions"
format: html
---


## Evolving a solution

The sheer number of possible solutions makes this a tricky problem to solve!

We could keep generating a very large number of random solutions, and this may work to eventually find a near-optimal solution, but could be extremely time-consuming and resource-intensive, requiring many hours of compute power.

Instead, let's try taking some inspiration from the natural world and **evolving** our solutions until they are as good as can be.

:::{.callout-tip}
This is a big part of the field of operational research, with certain algorithms like NSGA-II being well-known and defined, and implemented in libraries that you can reuse. However, you can also create your own genetic algorithms or modify approaches like NSGA-II, as done in [Allen et al. and their work on hyperacute stroke unit modelling](https://github.com/MichaelAllen1966/stroke_unit_location/blob/master/bmj_open_paper/bmj_open_stroke_unit_location_paper_supplementary_material-1.pdf).
:::

:::{.callout-note}
Due to the requirements for solutions to follow certain rules, evolving our solutions is somewhat more complex than in the case of our location allocation problem, where any combination of centres was theoretically 'valid'. In that instance, we could randomly permute or mix solutions with no concerns surrounding what the output looked like beyond not being an exact duplicate of an already-evaluated solution. Here, with a need to generate a solution that conforms to rules like the dispatcher's patch being continuous and all regions being allocated to one (and only one) dispatcher.
:::

So what will the process look like in this case?

- We will generate a new random solution using our function from the previous section
- We will evaluate that solution
    - While we will initially be evaluating this solution against a single metric, the same approach could be applied when scoring against multiple metrics
- If this solution is worse than the current status quo, we will generate a new random solution (and keep doing so until we find a solution that performs 'better' than the current status quo)
- If this solution is better than the current status quo, we will then start to evolve this solution
    - for each 'player' (in this case, our dispatchers), we will randomly add or remove a small number of their regions and allocate it to one of the other players for whom it would be valid territory (i.e. they share a boundary with the territory in question)
        - we will generate many of these variants per round
        - we will then assess the performance of each of these solutions
        - several of the best solutions (a parameter we will be able to vary) will be retained at this point, going on to form a new population of solutions we can continue to loop through, tweak, and recheck the performance of
            - rather than the 'child' solutions replacing the 'parents', we will keep both at each stage, evaluating them all on their merits rather than always assuming the 'child' strategies will be better
            - note that general recommendations are that ðº - the population size - should be at least 10 times larger than Î¼ - the number of solutions we keep in each generation
            - it's also recommended that ðº / Î¼ should leave no remainder
    - we will continue this process until there has been no improvement for several rounds of attempts
        - the number of rounds for which there is no improvement will be a parameter we can vary
- We will then store the performance of this solution, then start with a new random solution and repeat this for a certain number of solutions or period of time

:::{.callout-tip}
As the minor variation and evaluation of solutions is much quicker than generating brand new solutions with the method we developed in the previous chapter, we should see much faster movement towards a 'good' solution. This approach should therefore be more efficient than if we were to use the same amount of computational time generating and evaluating random solutions (though there is a small chance we land on a great solution at random!).

However, it should also be remembered that there is something to be said for a simple approach...

> â€œExperience shows that if the stakeholders (users of the model) can easily understand the methods used, they are more likely to trust the solution and use the model more confidently in the decision making processesâ€ - Meskarian R, Penn ML, Williams S, Monks T (2017)[^trustquote]

:::

[^trustquote]: Meskarian R, Penn ML, Williams S, Monks T (2017) A facility location model for analysis of current and future demand for sexual health services. PLoS ONE 12(8): e0183942. https://doi.org/10.1371/journal.pone.0183942


## Local and Global Optima

![](assets/2025-02-11-10-35-43.png)[^imglocaloptima]

[^imglocaloptima]: A genetic algorithm for calculating minimum distance between convex and concave bodies - Scientific Figure on ResearchGate. Available from: https://www.researchgate.net/figure/Local-versus-global-optimum_fig1_228563694 [accessed 9 Apr, 2024]

Evolutionary algorithms can have the issue of getting stuck in local optima - where they reach a 'good' solution and small tweaks in any direction lead to worse scores. However, outside of the 'sight' of the algorithm, there may be a better overall solution that exists.

While there are a range of ways this issue can be tackled, here we'll mainly be approaching it by working with several different random starting positions.

## Loading Previous Solutions

To start with, let's load our random solutions from the last chapter back in.

:::{.callout-warning}
Pickle is a convenient file format for storing dataframes and reloading them with important information like column types retained. This is important in situations like this where one of our columns is a more complex datatype that may not transfer well into a csv.

However, pickle is not particularly secure and you should only unpickle files from sources you trust as there is a risk of malicious code being injected and then executing on unpickling. Alternative formats such as [Feather](https://arrow.apache.org/docs/python/feather.html) and [Parquet](https://arrow.apache.org/docs/python/parquet.html) are generally regarded as more secure.
:::

```{python}
#| label: read-solutions-example

import pandas as pd

initial_solution_df = pd.read_pickle('solutions_example.pkl')

initial_solution_df.to_csv('solutions_example.csv')
```

Let's write a quick function to pull out the allocations from our solutions file, and turn that back into a dataframe we can work with.

```{python}
#| label: define-extract-allocations-df-function

def extract_allocation_df_from_solution_df(df, solution_rank, allocation_col_name, territory_col_name):
    row_of_interest = df[df['rank'] == solution_rank]
    owned_territory_dict = row_of_interest['allocations'].values[0]

    owned_territory_df = pd.DataFrame(
            [(key, value) for key, values in owned_territory_dict.items() for value in values],
            columns=[allocation_col_name, territory_col_name])
    return owned_territory_df
```

Let's now try this out to pull back and visualise our best solution.

```{python}
#| label: extract-best-solution

best_solution = extract_allocation_df_from_solution_df(
    initial_solution_df,
    solution_rank=1,
    allocation_col_name="centre_dispatcher_NEW",
    territory_col_name="LSOA11CD"
    )

best_solution
```

:::{.callout-note collapse="true"}
### Click here to view code from previous chapters for importing our historical boundary and demand data

```{python}
#| label: import-historical-boundaries-demand-repeat-earlier-chapter

import geopandas

lsoa_geojson_path = 'https://github.com/hsma-programme/h6_3c_interactive_plots_travel/raw/main/h6_3c_interactive_plots_travel/example_code/LSOA_2011_Boundaries_Super_Generalised_Clipped_BSC_EW_V4.geojson'

lsoa_boundaries = geopandas.read_file(lsoa_geojson_path)

xmin, xmax = 370000, 420000
ymin, ymax = 250000, 310000

bham_region = lsoa_boundaries.cx[xmin:xmax, ymin:ymax]

bham_region["region"] = bham_region["LSOA11NM"].str[:-5]

boundary_allocations_df = pd.read_csv("boundary_allocations.csv")

bham_region = pd.merge(
    bham_region,
    boundary_allocations_df,
    left_on="region",
    right_on="Region",
    how="left"
)

bham_region["centre_dispatcher"] = bham_region["Centre"].astype("str") + '-' + bham_region["Dispatcher"].astype("str")

demand = pd.read_csv("demand_pop_bham.csv")

bham_region = bham_region.merge(demand, on="LSOA11CD")

# Create df of original boundaries
grouped_dispatcher_gdf = bham_region.groupby("centre_dispatcher")

# Create a new GeoDataFrame for the boundaries of each group
boundary_list = []

for group_name, group in grouped_dispatcher_gdf:
    # Combine the polygons in each group into one geometry
    combined_geometry = group.unary_union

    # Get the boundary of the combined geometry
    boundary = combined_geometry.boundary

    # Add the boundary geometry and the group name to the list
    boundary_list.append({'group': group_name, 'boundary': boundary})

# Create a GeoDataFrame from the list of boundaries
grouped_dispatcher_gdf_boundary = geopandas.GeoDataFrame(boundary_list, geometry='boundary', crs=bham_region.crs)

```
:::

```{python}
#| label: visualise-historical-boundaries-and-best-sol

ax=bham_region.merge(best_solution, on="LSOA11CD").plot(column="centre_dispatcher_NEW")

# Visualise the historical boundaries
grouped_dispatcher_gdf_boundary.plot(
    ax=ax,
    linewidth=2,
    edgecolor="black"
)
```

And let's compare this with our worst-performing solution.

:::{.callout-tip collapse="true"}
### Click here to see the code
```{python}
#| label: visualise-worst-performing-solution
#| eval: false
worst_solution = extract_allocation_df_from_solution_df(
    initial_solution_df,
    solution_rank=20,
    allocation_col_name="centre_dispatcher_NEW",
    territory_col_name="LSOA11CD"
    )

ax=bham_region.merge(worst_solution, on="LSOA11CD").plot(column="centre_dispatcher_NEW")

# Visualise the historical boundaries
grouped_dispatcher_gdf_boundary.plot(
    ax=ax,
    linewidth=2,
    edgecolor="black"
)
```
:::

```{python}
#| echo: false
#| eval: true
worst_solution = extract_allocation_df_from_solution_df(
    initial_solution_df,
    solution_rank=20,
    allocation_col_name="centre_dispatcher_NEW",
    territory_col_name="LSOA11CD"
    )

ax=bham_region.merge(worst_solution, on="LSOA11CD").plot(column="centre_dispatcher_NEW")

# Visualise the historical boundaries
grouped_dispatcher_gdf_boundary.plot(
    ax=ax,
    linewidth=2,
    edgecolor="black"
)
```

## Writing our evolutionary algorithm

:::{.callout-tip collapse="true"}
### Click here for a reminder of what we are trying to code in our evolutionary algorithm

- If this solution is better than the current status quo, we will then start to evolve this solution
    - for each 'player' (in this case, our dispatchers), we will randomly add or remove a small number of their regions and allocate it to one of the other players for whom it would be valid territory (i.e. they share a boundary with the territory in question)
        - we will generate many of these variants per round
        - we will then assess the performance of each of these solutions
        - several of the best solutions (a parameter we will be able to vary) will be retained at this point, going on to form a new population of solutions we can continue to loop through, tweak, and recheck the performance of
            - rather than the 'child' solutions replacing the 'parents', we will keep both at each stage, evaluating them all on their merits rather than always assuming the 'child' strategies will be better
            - note that general recommendations are that ðº - the population size - should be at least 10 times larger than Î¼ - the number of solutions we keep in each generation
            - it's also recommended that ðº / Î¼ should leave no remainder
    - we will continue this process until there has been no improvement for several rounds of attempts
        - the number of rounds for which there is no improvement will be a parameter we can vary
- We will then store the performance of this solution, then start with a new random solution and repeat this for a certain number of solutions or period of time
:::


We're also going to reuse our 'add_neighbours_column()' function from before.

:::{.callout-note collapse="true"}
### Click here to view the add_neighbours_column() function from the previous chapter
```{python}
#| label: define-add-neighbours-column-function

def add_neighbors_column(gdf):
    """
    Adds a column to the GeoDataFrame containing lists of indices of neighboring polygons
    based on the 'touches' method.
    """
    gdf = gdf.copy()
    neighbors = []
    for idx, geom in gdf.geometry.items():
        touching = gdf[gdf.geometry.touches(geom)]["LSOA11CD"].tolist()
        neighbors.append(touching)

    gdf["neighbors"] = neighbors
    return gdf
```

:::


```{python}
#| label: define-permutation-functions

import random
from shapely.strtree import STRtree

def find_border_dispatchers(row, df, allocation_colname='centre_dispatcher_NEW'):
    current_dispatcher = row[allocation_colname]
    neighbors = row['neighbors']

    # Get dispatchers of neighboring LSOAs
    neighboring_dispatchers = {
        df.loc[df['LSOA11CD'] == neighbor, allocation_colname].values[0]
        for neighbor in neighbors if not df[df['LSOA11CD'] == neighbor].empty
    }

    # Filter to only different dispatchers
    border_dispatchers = list(neighboring_dispatchers - {current_dispatcher})

    return border_dispatchers if border_dispatchers else []

def is_solution_continuous(solution_gdf, tree, new_allocation_colname):
    """
    Uses spatial indexing to quickly check if dispatchers have disjoint regions.
    """

    # Get geometries grouped by dispatcher
    dispatcher_groups = solution_gdf.dissolve(by=new_allocation_colname)

    for geom in dispatcher_groups.geometry:
        neighbors = tree.query(geom)  # Get intersecting geometries
        if len(neighbors) > 1 and geom.geom_type == "MultiPolygon":
            return False  # Found disjoint regions

    return True

def is_continuous_after_swap(solution_gdf, lsoa, new_dispatcher, new_allocation_colname, tree):
    """
    Checks if assigning 'lsoa' to 'new_dispatcher' maintains contiguous regions.
    This version avoids making a full DataFrame copy.
    """
    original_dispatcher = solution_gdf.loc[solution_gdf["LSOA11CD"] == lsoa, new_allocation_colname].values[0]

    # Temporarily assign new dispatcher
    solution_gdf.loc[solution_gdf["LSOA11CD"] == lsoa, new_allocation_colname] = new_dispatcher

    # Check continuity
    is_valid = is_solution_continuous(solution_gdf, tree, new_allocation_colname)

    # Revert change immediately (avoiding full copy overhead)
    solution_gdf.loc[solution_gdf["LSOA11CD"] == lsoa, new_allocation_colname] = original_dispatcher

    #return is_valid
    return True

def assign_new_dispatcher(row, solution_gdf, border_colname, permutation_chance_per_border, new_allocation_colname, tree):
        """
        Attempts to assign a new dispatcher while keeping the solution continuous.
        """
        if not row[border_colname]:  # If no bordering dispatchers, keep the original
            return row[new_allocation_colname]

        elif random.uniform(0.0, 1.0) < permutation_chance_per_border:
            random_dispatcher = random.choice(row[border_colname])  # Randomly select from border dispatchers

            # Check if assigning this dispatcher keeps the solution contiguous
            if is_continuous_after_swap(solution_gdf, row["LSOA11CD"], random_dispatcher, new_allocation_colname, tree):
                print(f"Swapped {row['LSOA11CD']} to {random_dispatcher}")
                return random_dispatcher
            else:
                return row[new_allocation_colname]  # Default to original allocation
        else:
            return row[new_allocation_colname]

```

```{python}
#| label: define-initial-evolutionary-function

def create_evolved_solutions(
        initial_solution_df, geodataframe,
        join_col_left, join_col_right,
        original_allocation_colname='centre_dispatcher',
        random_solution_allocation_colname='centre_dispatcher_NEW',
        new_allocation_colname='centre_dispatcher_evolved',
        border_colname='border_dispatchers',
        permutation_chance_per_border=0.2,
        population_size=1
    ):
    """
    Generates evolved dispatcher allocations while ensuring that all regions remain contiguous.
    """

    # Merge initial solution with geodataframe to keep it as a geodataframe
    initial_solution_gdf = geodataframe.merge(initial_solution_df, left_on=join_col_left, right_on=join_col_right)

    # Compute neighbors and border dispatchers
    initial_solution_gdf = add_neighbors_column(initial_solution_gdf)
    initial_solution_gdf[border_colname] = initial_solution_gdf.apply(find_border_dispatchers, axis=1, df=initial_solution_gdf)

    # Build an R-tree for fast spatial searches
    tree = STRtree(initial_solution_gdf.geometry)

    new_allocation_dfs = []

    # Include new_allocation_colname from the start
    simplified_allocation_df = initial_solution_gdf[[random_solution_allocation_colname, 'LSOA11CD', border_colname, "geometry"]].copy()
    simplified_allocation_df[new_allocation_colname] = simplified_allocation_df[random_solution_allocation_colname]

    for i in range(population_size):
        evolved_df = simplified_allocation_df.copy(deep=True)

        evolved_df[new_allocation_colname] = evolved_df.apply(lambda row: assign_new_dispatcher(row, evolved_df, border_colname, permutation_chance_per_border, new_allocation_colname, tree), axis=1)

        #for idx, row in evolved_df.iterrows():
        #    new_dispatcher = assign_new_dispatcher(row, evolved_df, border_colname, permutation_chance_per_border, new_allocation_colname, tree)
        #    evolved_df.at[idx, new_allocation_colname] = new_dispatcher

        new_allocation_dfs.append(evolved_df.copy(deep=True))

        del evolved_df

    return new_allocation_dfs
```


```{python}
#| label: generate-one-solution

solution = create_evolved_solutions(
    best_solution,
    bham_region,
    join_col_left="LSOA11CD",
    join_col_right="LSOA11CD",
    population_size=1
)

solution[0]

```


Let's try generating more.

```{python}
#| label: generate-thirty-solutions

solution = create_evolved_solutions(
    best_solution,
    bham_region,
    join_col_left="LSOA11CD",
    join_col_right="LSOA11CD",
    population_size=30
)

solution[25]

```

### Confirming solutions are distinct

Let's confirm these solutions are distinct!

```{python}
#| label: check-distinct-solutions

print(f"There are {len(solution)} solutions generated")

def remove_duplicate_dataframes(df_list):
    """
    Removes duplicate dataframes from a list using hashing.

    Args:
        df_list (list of pd.DataFrame): List of pandas DataFrames.

    Returns:
        list of pd.DataFrame: List with duplicates removed.
    """
    seen_hashes = set()
    unique_dfs = []

    for df in df_list:
        df_hash = pd.util.hash_pandas_object(df[['LSOA11CD','centre_dispatcher_evolved']], index=True).values.tobytes()  # Ensure a hashable type
        if df_hash not in seen_hashes:
            seen_hashes.add(df_hash)
            unique_dfs.append(df)

    return unique_dfs

print(f"There are {len(remove_duplicate_dataframes(solution))} unique solutions generated")

```

### Confirming solutions are valid

We will first create a df showing the boundaries of our plots in our original solution.

```{python}
#| label: get-starter-solution-boundaries

# Create df of original boundaries
grouped_dispatcher_gdf_starting_solution = bham_region.merge(best_solution, on="LSOA11CD").groupby("centre_dispatcher_NEW")

# Create a new GeoDataFrame for the boundaries of each group
boundary_list = []

for group_name, group in grouped_dispatcher_gdf_starting_solution:
    # Combine the polygons in each group into one geometry
    combined_geometry = group.unary_union

    # Get the boundary of the combined geometry
    boundary = combined_geometry.boundary

    # Add the boundary geometry and the group name to the list
    boundary_list.append({'group': group_name, 'boundary': boundary})

# Create a GeoDataFrame from the list of boundaries
grouped_dispatcher_gdf_starting_solution = geopandas.GeoDataFrame(boundary_list, geometry='boundary', crs=bham_region.crs)
```

#### One Solution

Let's plot a random solution.

```{python}
#| label: plot-single-solution

ax = solution[25].plot(column="centre_dispatcher_evolved", legend=True)

# Plot historical boundaries
grouped_dispatcher_gdf_starting_solution.plot(ax=ax, linewidth=2, edgecolor="black")

ax.axis("off")  # Hide axes for better visualization
```

#### Many solutions

Let's now plot each of these solutions to confirm they are valid.

Now let's plot 10 of the solutions

```{python}
#| label: plot-ten-solutions
import matplotlib.pyplot as plt

fig, axes = plt.subplots(5, 3, figsize=(15, 15))  # Adjust figure size
axes = axes.flatten()  # Flatten in case of a 2D array of axes

for i, df in enumerate(solution[:15]):
    ax = axes[i]

    df.plot(column="centre_dispatcher_evolved",
                                              ax=ax, legend=False)

    # Plot historical boundaries
    grouped_dispatcher_gdf_starting_solution.plot(ax=ax, linewidth=2, edgecolor="black")

    ax.set_title(f"Solution {i+1}")
    ax.axis("off")  # Hide axes for better visualization

# Hide any unused subplots
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()
```

Now let's evaluate our evolved solutions.

:::{.callout-note collapse="true"}
### Click here to view our 'evaluate_solution()' function from the previous chapter

```{python}
#| label: define-evaluation-functions
def evaluate_solution(gdf, allocation_column='centre_dispatcher_NEW',
                      demand_column="demand"):
    grouped_by_dispatcher = gdf.groupby(allocation_column)[[demand_column]].sum()
    mean_demand = grouped_by_dispatcher['demand'].mean()

    grouped_by_dispatcher['difference_from_mean'] = (grouped_by_dispatcher['demand'] - mean_demand).astype('int')

    return abs(grouped_by_dispatcher['difference_from_mean']).mean().round(1)

def evaluate_solution_dict(solution_dict, gdf,
                            allocation_column='centre_dispatcher',
                            demand_column="demand", territory_unit_column="LSOA11CD"):

    owned_territory_df = pd.DataFrame(
            [(key, value) for key, values in solution_dict.items() for value in values],
            columns=[f"{allocation_column}_NEW", territory_unit_column])
    gdf = pd.merge(gdf, owned_territory_df, on=territory_unit_column, how="left")

    grouped_by_dispatcher = gdf.groupby(f"{allocation_column}_NEW")[[demand_column]].sum()
    mean_demand = grouped_by_dispatcher['demand'].mean()

    grouped_by_dispatcher['difference_from_mean'] = (grouped_by_dispatcher['demand'] - mean_demand).astype('int')

    return abs(grouped_by_dispatcher['difference_from_mean']).mean().round(1)
```

:::

:::{.callout-tip}
Coming soon!
:::

We will now take a specified portion of these solutions, evolve them, evaluate them again, and continue.

We will also start tracking how good the best solution we are achieving is after each evolution.

We will repeat this 1000 times, plotting the value for our best solution over time to see how much better we can make the solution with sufficient permutations.

:::{.callout-tip}
Coming soon!
:::

Let's plot what we started with versus our best 10 solutions at the end of the process.







Here is our final start-to-finish code for generating and evaluating the solutions.

:::{.callout-tip}
Coming soon!
:::
